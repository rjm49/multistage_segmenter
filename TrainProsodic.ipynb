{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import os\n",
    "import scipy\n",
    "\n",
    "from sklearn import preprocessing, svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.linear_model.logistic import LogisticRegression\n",
    "from sklearn.metrics.classification import classification_report\n",
    "\n",
    "from mseg.common import TRAIN_FILE_DEFAULT, TEST_FILE_DEFAULT, read_file\n",
    "\n",
    "overwrite_pkl = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dissect(data, selection_columns):\n",
    "    headers = [data[0][i] for i in selection_columns]\n",
    "    words = [r[5] for r in data]\n",
    "    samples = [[float(r[i]) for i in selection_columns] for r in data]\n",
    "    classes = [float(r[6]) for r in data]\n",
    "    return (headers, words, samples, classes)\n",
    "\n",
    "# # Utility function to report best scores\n",
    "# def report(grid_scores, n_top=3):\n",
    "#     top_scores = sorted(grid_scores, key=itemgetter(1), reverse=True)[:n_top]\n",
    "#     for i, score in enumerate(top_scores):\n",
    "#         print(\"Model with rank: {0}\".format(i + 1))\n",
    "#         print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "#               score.mean_validation_score,\n",
    "#               np.std(score.cv_validation_scores)))\n",
    "#         print(\"Parameters: {0}\".format(score.parameters))\n",
    "#         print(\"\")\n",
    "        \n",
    "        \n",
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = numpy.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of tokens loaded: 61237\n",
      "./models//home/rjm49/Dropbox/nlp_alta/recreate_LG/tt_data/eval1-prosodicFeats_norm_train.csv -SVM->  ./models/prosodic_models/eval1-probabilities.dat\n",
      "number of tokens loaded: 6792\n",
      "n= 59098  p= 2139\n",
      "wgt= 27.62879850397382\n",
      "made dir for pickled model: ./models/prosodic_models/pkl\n",
      "range(-5, 17, 2)\n",
      "c_range (0.5, 50, 5000)\n",
      "range(-15, 5, 2)\n",
      "gamma_range (0.0005, 0.05, 5.0, 500)\n",
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rjm49/anaconda3/envs/wfst/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    8.4s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   38.3s\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  1.0min finished\n",
      "/home/rjm49/anaconda3/envs/wfst/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with rank: 1\n",
      "Mean validation score: 0.746 (std: 0.020)\n",
      "Parameters: {'C': 136.05895700345587}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.746 (std: 0.020)\n",
      "Parameters: {'C': 69.59104863689879}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.746 (std: 0.020)\n",
      "Parameters: {'C': 305.2655777484975}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.746 (std: 0.020)\n",
      "Parameters: {'C': 82.21248019937761}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.746 (std: 0.020)\n",
      "Parameters: {'C': 297.1112638540757}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.746 (std: 0.020)\n",
      "Parameters: {'C': 181.25598088889748}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.746 (std: 0.020)\n",
      "Parameters: {'C': 175.17239598565877}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.746 (std: 0.020)\n",
      "Parameters: {'C': 268.538794820802}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.746 (std: 0.020)\n",
      "Parameters: {'C': 1.677192674327993}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.746 (std: 0.020)\n",
      "Parameters: {'C': 19.530034658711042}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.746 (std: 0.020)\n",
      "Parameters: {'C': 209.5465553169515}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.746 (std: 0.020)\n",
      "Parameters: {'C': 68.6929488150411}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.746 (std: 0.020)\n",
      "Parameters: {'C': 107.19500120000885}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.746 (std: 0.020)\n",
      "Parameters: {'C': 377.7721337448584}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.746 (std: 0.020)\n",
      "Parameters: {'C': 130.97669371518995}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.746 (std: 0.020)\n",
      "Parameters: {'C': 10.19018657756902}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.746 (std: 0.020)\n",
      "Parameters: {'C': 55.42316161921374}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.746 (std: 0.020)\n",
      "Parameters: {'C': 424.68774001985156}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.746 (std: 0.020)\n",
      "Parameters: {'C': 119.57501290143782}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.746 (std: 0.020)\n",
      "Parameters: {'C': 19.86889231438585}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.746 (std: 0.020)\n",
      "Parameters: {'C': 524.8028782281776}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.746 (std: 0.020)\n",
      "Parameters: {'C': 62.45580036692174}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.746 (std: 0.020)\n",
      "Parameters: {'C': 0.6471582414738436}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.746 (std: 0.020)\n",
      "Parameters: {'C': 40.101389394601576}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.746 (std: 0.020)\n",
      "Parameters: {'C': 439.33630270579096}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.746 (std: 0.020)\n",
      "Parameters: {'C': 226.82831337480985}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.746 (std: 0.020)\n",
      "Parameters: {'C': 149.624445545044}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.746 (std: 0.020)\n",
      "Parameters: {'C': 216.77671165315817}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.746 (std: 0.020)\n",
      "Parameters: {'C': 11.208175380446022}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.746 (std: 0.020)\n",
      "Parameters: {'C': 62.529613498711456}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.746 (std: 0.020)\n",
      "Parameters: {'C': 56.47120803513466}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.746 (std: 0.020)\n",
      "Parameters: {'C': 198.4249293935255}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.746 (std: 0.020)\n",
      "Parameters: {'C': 27.38072686895582}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.746 (std: 0.020)\n",
      "Parameters: {'C': 61.90884103329631}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.746 (std: 0.020)\n",
      "Parameters: {'C': 180.38416620639174}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.746 (std: 0.020)\n",
      "Parameters: {'C': 50.24628484817353}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.746 (std: 0.020)\n",
      "Parameters: {'C': 192.41046292973087}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.746 (std: 0.020)\n",
      "Parameters: {'C': 85.08190357451288}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.746 (std: 0.020)\n",
      "Parameters: {'C': 58.5367440851173}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.746 (std: 0.020)\n",
      "Parameters: {'C': 14.244947691284704}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.746 (std: 0.020)\n",
      "Parameters: {'C': 62.40106463798637}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.746 (std: 0.020)\n",
      "Parameters: {'C': 134.649462016357}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.746 (std: 0.020)\n",
      "Parameters: {'C': 173.64319296915303}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.746 (std: 0.020)\n",
      "Parameters: {'C': 397.8987284592162}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.746 (std: 0.020)\n",
      "Parameters: {'C': 68.2418580347438}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.746 (std: 0.020)\n",
      "Parameters: {'C': 9.767805483211056}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.746 (std: 0.020)\n",
      "Parameters: {'C': 40.043817002401596}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.746 (std: 0.020)\n",
      "Parameters: {'C': 16.77174935407578}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.746 (std: 0.020)\n",
      "Parameters: {'C': 23.79164082816437}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.746 (std: 0.020)\n",
      "Parameters: {'C': 28.186052825058216}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.746 (std: 0.020)\n",
      "Parameters: {'C': 15.789194254608255}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.746 (std: 0.020)\n",
      "Parameters: {'C': 33.21855345479816}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.746 (std: 0.020)\n",
      "Parameters: {'C': 13.356855460830113}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.746 (std: 0.020)\n",
      "Parameters: {'C': 14.947248362746768}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.746 (std: 0.020)\n",
      "Parameters: {'C': 4.834996568621835}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.746 (std: 0.020)\n",
      "Parameters: {'C': 76.5482196370375}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.746 (std: 0.020)\n",
      "Parameters: {'C': 63.35694669345278}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.746 (std: 0.020)\n",
      "Parameters: {'C': 47.82339624134916}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.746 (std: 0.020)\n",
      "Parameters: {'C': 35.12871906229861}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.746 (std: 0.020)\n",
      "Parameters: {'C': 215.64946140885866}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.746 (std: 0.020)\n",
      "Parameters: {'C': 461.82725814669914}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.746 (std: 0.020)\n",
      "Parameters: {'C': 23.96879060365143}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.746 (std: 0.020)\n",
      "Parameters: {'C': 0.5782740933524353}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.746 (std: 0.020)\n",
      "Parameters: {'C': 184.70735828051946}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.746 (std: 0.020)\n",
      "Parameters: {'C': 43.60988001592913}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.746 (std: 0.020)\n",
      "Parameters: {'C': 60.01212316828058}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.746 (std: 0.020)\n",
      "Parameters: {'C': 37.72001256566499}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.746 (std: 0.020)\n",
      "Parameters: {'C': 14.613236691941815}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.746 (std: 0.020)\n",
      "Parameters: {'C': 28.809512903346008}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.746 (std: 0.020)\n",
      "Parameters: {'C': 2.065563826264008}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.746 (std: 0.020)\n",
      "Parameters: {'C': 10.926305612409285}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.746 (std: 0.020)\n",
      "Parameters: {'C': 298.4646184606178}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.746 (std: 0.020)\n",
      "Parameters: {'C': 139.76236981919254}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.746 (std: 0.020)\n",
      "Parameters: {'C': 5.76126231849409}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.746 (std: 0.020)\n",
      "Parameters: {'C': 42.87160419007482}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.746 (std: 0.020)\n",
      "Parameters: {'C': 401.5778394631786}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.746 (std: 0.020)\n",
      "Parameters: {'C': 25.62996036992778}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.746 (std: 0.020)\n",
      "Parameters: {'C': 24.243628249279347}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.746 (std: 0.020)\n",
      "Parameters: {'C': 123.6105299129387}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.746 (std: 0.020)\n",
      "Parameters: {'C': 229.56880008631444}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.746 (std: 0.020)\n",
      "Parameters: {'C': 223.46156792739177}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.746 (std: 0.020)\n",
      "Parameters: {'C': 278.4257292756956}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.746 (std: 0.020)\n",
      "Parameters: {'C': 43.04459906369944}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.746 (std: 0.020)\n",
      "Parameters: {'C': 43.16845862459252}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.746 (std: 0.020)\n",
      "Parameters: {'C': 1.9273308338479092}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.746 (std: 0.020)\n",
      "Parameters: {'C': 26.29319184866471}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.746 (std: 0.020)\n",
      "Parameters: {'C': 128.42255869636122}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.746 (std: 0.020)\n",
      "Parameters: {'C': 129.7028718006064}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.746 (std: 0.020)\n",
      "Parameters: {'C': 20.887335324574842}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.746 (std: 0.020)\n",
      "Parameters: {'C': 113.64093761673372}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.746 (std: 0.020)\n",
      "Parameters: {'C': 169.9095387626531}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.746 (std: 0.020)\n",
      "Parameters: {'C': 15.196346878787642}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.746 (std: 0.020)\n",
      "Parameters: {'C': 90.92798503233833}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.746 (std: 0.020)\n",
      "Parameters: {'C': 161.51273728910738}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.746 (std: 0.020)\n",
      "Parameters: {'C': 70.2502505364562}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.746 (std: 0.020)\n",
      "Parameters: {'C': 7.025098621257718}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.746 (std: 0.020)\n",
      "Parameters: {'C': 63.60192389762486}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.746 (std: 0.020)\n",
      "Parameters: {'C': 65.06059727256924}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.746 (std: 0.020)\n",
      "Parameters: {'C': 199.8423015924015}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.746 (std: 0.020)\n",
      "Parameters: {'C': 104.9974515017329}\n",
      "\n",
      "COMPARING CLF PARAMS WITH BEST PARAMS (shd be same)\n",
      "{'C': 136.05895700345587, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'warn', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'warn', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "None\n",
      "LogisticRegression(C=136.05895700345587, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='warn', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "no test cases 6792\n",
      "[[0.95848195 0.48365572]\n",
      " [0.17942887 1.80634976]\n",
      " [0.26578216 1.45502774]\n",
      " ...\n",
      " [0.13342031 2.08021949]\n",
      " [0.23807677 1.55183992]\n",
      " [3.65196979 0.02628236]]\n",
      "TEST: Number of mislabelled points out of a total 6792 points : 240\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.97      0.98      6531\n",
      "         1.0       0.53      0.74      0.62       261\n",
      "\n",
      "    accuracy                           0.96      6792\n",
      "   macro avg       0.76      0.86      0.80      6792\n",
      "weighted avg       0.97      0.96      0.97      6792\n",
      "\n",
      "wrote report file <_io.TextIOWrapper name='./models/prosodic_models/eval1-report-LR.txt' mode='w' encoding='UTF-8'>\n",
      "wrote predictions file: <_io.TextIOWrapper name='./models/prosodic_models/eval1-probabilities.dat' mode='w' encoding='UTF-8'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rjm49/anaconda3/envs/wfst/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1681: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(self.predict_proba(X))\n"
     ]
    }
   ],
   "source": [
    "    base_dir = \"./models\"\n",
    "    pm_dir = \"prosodic_models\"\n",
    "    tr_file = \"/home/rjm49/Dropbox/nlp_alta/recreate_LG/tt_data/eval1-prosodicFeats_norm_train.csv\"\n",
    "    tt_file = \"/home/rjm49/Dropbox/nlp_alta/recreate_LG/tt_data/eval1-prosodicFeats_norm_test.csv\"\n",
    "    test_fname = \"eval1\"\n",
    "    use_lr = True\n",
    "    \n",
    "    n_samples = -1\n",
    "    cache = 800\n",
    "    \n",
    "#     tr_data = read_file(os.path.join(base_dir, tr_file), ',', skip_header=True)\n",
    "    tr_data = read_file(tr_file, ',', skip_header=True)\n",
    "    \n",
    "    if not use_lr:\n",
    "        n_samples = 6000\n",
    "        out_fname = test_fname+\"-probabilities.dat\"\n",
    "        report_fname = test_fname+\"-report.txt\"\n",
    "    else: \n",
    "        out_fname = test_fname+\"-probabilities.dat\"\n",
    "        report_fname = test_fname+\"-report-LR.txt\"\n",
    "\n",
    "    out_file = os.path.join(base_dir, pm_dir, out_fname)\n",
    "    report_fname = os.path.join(base_dir, pm_dir, report_fname)\n",
    "    #clear extant predictions file\n",
    "    if(os.path.exists(out_file)):\n",
    "        os.remove(out_file)\n",
    "        print(\"removed\",out_file)\n",
    "        \n",
    "    print(base_dir+\"/\"+tr_file+\" -SVM-> \",out_file)\n",
    "    \n",
    "\n",
    "#     test_data = read_file(os.path.join(base_dir, test_fname), ',', skip_header=True)\n",
    "    test_data = read_file(tt_file, ',', skip_header=True)\n",
    "    \n",
    "    #sel = [12,13,14,15,21,22,23,24]\n",
    "    sel = range(7,30)\n",
    "    #sel = [8,21,29, 24,25,27]\n",
    "\n",
    "    (_, _, tr_samples, tr_classes) = dissect(tr_data, sel)\n",
    "    (_, te_words, te_samples, te_classes) = dissect(test_data, sel)\n",
    "       \n",
    "    if n_samples>0:\n",
    "        tr_samples, _, tr_classes, _ =  train_test_split(tr_samples, tr_classes, train_size=n_samples, stratify=tr_classes) \n",
    "    \n",
    "    p = sum(c==1.0 for c in tr_classes) # count the positive instances\n",
    "    n = len(tr_classes) - p # derive the negative instances\n",
    "    print(\"n=\",n,\" p=\",p)\n",
    "    wgt=float(n)/float(p) # cast and divide\n",
    "    print(\"wgt=\",wgt)\n",
    "#     classWeight = { 1: wgt }\n",
    "    \n",
    "    \n",
    "    #tr_samples, te_samples, tr_classes, te_classes = train_test_split(samples, classes, test_size=0.20, random_state=0, stratify=classes)\n",
    "                    \n",
    "    tr_samples = numpy.array(tr_samples)\n",
    "    scaler = preprocessing.StandardScaler()\n",
    "    tr_samples = scaler.fit_transform(tr_samples)\n",
    "    \n",
    "             \n",
    "    clf = None\n",
    "    best_params = None\n",
    "    #override the defaults with the results of a grid search if desired (takes a while)\n",
    "    \n",
    "        \n",
    "    #pickled = False\n",
    "    pkl_dir = os.path.join(base_dir, pm_dir, \"pkl\")\n",
    "    pickled_model = os.path.join(pkl_dir, \"svm_classifier.pkl\")\n",
    "    \n",
    "    if(os.path.exists(pickled_model) and not overwrite_pkl):\n",
    "        clf = joblib.load(pickled_model)\n",
    "        clf.set_params(verbose=True)\n",
    "        print(\"loaded pickled model...\", pickled_model)\n",
    "    \n",
    "    else:\n",
    "        if not os.path.exists(pkl_dir): #output dir doesn't exist so make it\n",
    "            os.makedirs(pkl_dir)\n",
    "            print(\"made dir for pickled model:\", pkl_dir)\n",
    "        \n",
    "        (cmin, cmax, cstep) = (-5,  17,  2)\n",
    "        cr = range(cmin,cmax,cstep)\n",
    "        print(cr)\n",
    "        #c_range = [ pow(2, y) for y in cr]\n",
    "        #c_range =(0.005, 0.5, 5, 50, 500, 5000, 50000)\n",
    "        c_range = (0.5, 50, 5000)\n",
    "        print('c_range', c_range)\n",
    "    \n",
    "        gmin, gmax, gstep = -15, 5, 2\n",
    "        gr = range(gmin, gmax, gstep)\n",
    "        print(gr)\n",
    "        #gamma_range = [ pow(2, y) for y in gr ]\n",
    "        #gamma_range = (0.00005, 0.0005, 0.005, 0.05, 0.5, 5.0, 50, 500)\n",
    "        gamma_range = (0.0005, 0.05, 5.0, 500)\n",
    "        \n",
    "        print('gamma_range', gamma_range)\n",
    "        \n",
    "        c_dist =  scipy.stats.expon(scale=100)\n",
    "        gamma_dist = scipy.stats.expon(scale=.01)\n",
    "        \n",
    "        if use_lr:\n",
    "            estr = LogisticRegression(class_weight='balanced')\n",
    "#             estr = LogisticRegression()\n",
    "            param_dist={'C': c_dist }\n",
    "        else:\n",
    "            estr = svm.SVC(kernel='rbf', cache_size=800, probability=True, class_weight='balanced' )\n",
    "            #estr = svm.LinearSVC(class_weight='balanced')\n",
    "            param_dist={'C': c_dist , 'gamma': gamma_dist}\n",
    "            \n",
    "        \n",
    "        #searcher = RandomizedSearchCV(estr, param_distributions=param_dist, n_iter=100, n_jobs=-1, cv=5, verbose=True ) #, scoring=\"recall\")\n",
    "        searcher = RandomizedSearchCV(estr, param_distributions=param_dist, n_iter=100, n_jobs=-1, verbose=True, scoring=\"recall\")\n",
    "        searcher.fit(tr_samples,tr_classes)\n",
    "        report(searcher.cv_results_)\n",
    "        clf = searcher.best_estimator_         \n",
    "\n",
    "        print(\"COMPARING CLF PARAMS WITH BEST PARAMS (shd be same)\")\n",
    "        print(clf.get_params())\n",
    "        print(best_params)\n",
    "        \n",
    "        joblib.dump(clf, pickled_model)\n",
    "        \n",
    "    print(clf)\n",
    "\n",
    "#     print(\"FITTING\"     \n",
    "#     clf.set_params(verbose=True)\n",
    "#     clf.fit(tr_samples, tr_classes)\n",
    "#     print(clf\n",
    "     \n",
    "    \n",
    "    #NOW TO TEST AGAINST HELD-OUT/TEST DATA\n",
    "    te_samples = scaler.transform(te_samples)\n",
    "    \n",
    "    print(\"no test cases\", len(te_samples))\n",
    "    \n",
    "    predictions = -1.0 * clf.predict_log_proba(te_samples)\n",
    "#     predictions = clf.predict_proba(te_samples) #this is a list of pairs of probs in form [ [1-p, p],  ... ]\n",
    "    print(predictions)\n",
    "    predicted_classes = clf.predict(te_samples)\n",
    "    \n",
    "    print(\"TEST: Number of mislabelled points out of a total %d points : %d\" % (len(te_samples),(te_classes != predicted_classes).sum()))\n",
    "    print(classification_report(te_classes, predicted_classes))\n",
    "\n",
    "    \n",
    "    rpt = open(report_fname, \"w\")\n",
    "    rpt.write(classification_report(te_classes, predicted_classes))\n",
    "    rpt.write(\"\\n\")\n",
    "    rpt.close()\n",
    "    print(\"wrote report file\", rpt)\n",
    "    \n",
    "    pred_file = open(out_file,\"w\")\n",
    "    pred_file.write(\"labels 0 1\\n\") #this emulates an earlier file format for compatibility\n",
    "    for word, prob_tuple, y_hat, y in zip(te_words,predictions,predicted_classes,te_classes):\n",
    "        pred_file.write(\"%d %d %f %f %s\\n\" % (y_hat, y,prob_tuple[0],prob_tuple[1],word))\n",
    "\n",
    "    pred_file.close()\n",
    "    print(\"wrote predictions file:\",pred_file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
